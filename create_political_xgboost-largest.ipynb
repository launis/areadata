{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datojen haku ja esikäsittely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from set_path import set_path\n",
    "mainpath, path = set_path('areadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read_and_prepare_data  read from file\n",
      "read_post_muncipalities  read from file\n"
     ]
    }
   ],
   "source": [
    "from read_and_prepare_data import read_and_prepare_data\n",
    "stat, post, kunta_stat, vaalidata = read_and_prepare_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selected_cols import selected_cols\n",
    "numeric_features, categorical_features = selected_cols(largeset=False, parties=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import  mutual_info_classif\n",
    "import pandas as pd\n",
    "\n",
    "from draw_and_create_clusters import create_kmeans_clusters \n",
    "\n",
    "from prepare_and_scale_data import prepare_and_scale_data\n",
    "from create_prediction import select_kbest\n",
    "from select_columns_and_clean_data import select_columns_and_clean_data\n",
    "\n",
    "from draw_and_create_clusters import draw_pca, drawTSNE,  display_scree_plot, display_circles, display_parallel_coordinates_centroids, display_factorial_planes\n",
    "from delete_outliers import delete_outliers\n",
    "\n",
    "from shap_Xboost import shap_Xboost\n",
    "from shap_proba_individual import shap_proba_individual, print_individual, print_reason, print_individual_waterfall\n",
    "from shap_vals import shap_vals\n",
    "from print_examples import print_examples\n",
    "import shap\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "\n",
    "selected = stat[(stat['muncipality_code']==49)].copy()\n",
    "selected_vaalidata = vaalidata[(vaalidata['Kuntanumero']==49)].copy()\n",
    "post_included = post[post['muncipality_code']==49]['postcode'].copy()\n",
    "\n",
    "\n",
    "selected = stat[(stat['muncipality_code']==91)].copy()\n",
    "selected_vaalidata = vaalidata[(vaalidata['Kuntanumero']==91)].copy()\n",
    "post_included = post[post['muncipality_code']==91]['postcode'].copy()\n",
    "\n",
    "selected = stat[stat['area_code']=='FI1B1'].copy()\n",
    "selected_vaalidata = vaalidata[vaalidata['area_code']=='FI1B1'].copy()\n",
    "post_included = post[post['area_code']=='FI1B1'].copy()\n",
    "\n",
    "selected = stat.copy()\n",
    "selected_vaalidata = vaalidata.copy()\n",
    "post_included = post.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model\n",
      "[0]\ttrain-merror:0.18308\ttest-merror:0.32828\n",
      "Multiple eval metrics have been passed: 'test-merror' will be used for early stopping.\n",
      "\n",
      "Will train until test-merror hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[27]\ttrain-merror:0.00000\ttest-merror:0.25084\n",
      "\n",
      "testing\n",
      "Start with xgb.cv params: merror: 0.25925933333333334\n",
      "Best xgb.cv params: max_depth 6, min_child_weight 1, merror: 0.25925933333333334\n",
      "Best xgb.cv params: gamma 0.0, merror: 0.25925933333333334\n",
      "Best xgb.cv params: lambda 1.0, alpha 0.0, merror: 0.25925933333333334\n",
      "Best xgb.cv params: colsample_bytree 1.0, subsample 0.6, merror: 0.25883833333333334\n",
      "Best xgb.cv params: eta 0.2, merror: 0.26473066666666667\n",
      "Found hyperparameters with 1 rounds \n",
      "{'objective': 'multi:softmax', 'num_class': 8, 'booster': 'gbtree', 'eval_metric': 'merror', 'max_depth': 6, 'min_child_weight': 1, 'gamma': 0.0, 'lambda': 1.0, 'alpha': 0.0, 'colsample_bytree': 1.0, 'subsample': 0.6, 'eta': 0.2}\n",
      "\n",
      "[0]\ttrain-merror:0.22391\ttest-merror:0.30135\n",
      "Multiple eval metrics have been passed: 'test-merror' will be used for early stopping.\n",
      "\n",
      "Will train until test-merror hasn't improved in 50 rounds.\n",
      "Stopping. Best iteration:\n",
      "[31]\ttrain-merror:0.01599\ttest-merror:0.24916\n",
      "\n",
      "[0]\ttrain-merror:0.22391\ttest-merror:0.30135\n",
      "[31]\ttrain-merror:0.01599\ttest-merror:0.24916\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import  mutual_info_classif\n",
    "\n",
    "\n",
    "data, X, X_scale = prepare_and_scale_data(selected, pd.DataFrame(), numeric_features, categorical_features)\n",
    "\n",
    "from create_prediction import create_prediction\n",
    "values = data.sort_values(by=['Suurin_puolue numero'])['Suurin_puolue numero'].unique()\n",
    "j = 0\n",
    "for i in values:\n",
    "    data.loc[data['Suurin_puolue numero']==i, 'Suurin_puolue numero uusi numero'] = j\n",
    "    j = j + 1\n",
    "\n",
    "data.loc[:,'Suurin_puolue numero uusi numero'] = data['Suurin_puolue numero uusi numero'].astype(int) \n",
    "target = 'Suurin_puolue numero uusi numero'\n",
    "\n",
    "#Check\n",
    "#k_selected need to have correct values, if they are too large, evrything needs to be started again\n",
    "k_selected = 'all'\n",
    "\n",
    "test_size = 0.2\n",
    "\n",
    "#Scalers attributes\n",
    "kbest_score_func = mutual_info_classif\n",
    "#set values to model configuration attributes\n",
    "\n",
    "num_class = len(data['Suurin_puolue numero uusi numero'].unique()) #how many classes we are working with\n",
    "\n",
    "metric = 'merror'\n",
    "Skfold=False\n",
    "Verbose = False\n",
    "testing=True\n",
    "scaled = False\n",
    "\n",
    "params = {\n",
    "    # Parameters that we are going to tune.\n",
    "    'objective':'multi:softmax',\n",
    "    'num_class' : num_class,\n",
    "    'booster' : 'gbtree',\n",
    "    'eval_metric' : metric\n",
    "} \n",
    "\n",
    "filename_model = 'xgboost_largeparty'\n",
    "data, test, features_df, importance_df, model, params, y_pred, X_train, y_train, X_test, y_test = create_prediction(filename_model, path, data, data, target, kbest_score_func, metric, params, numeric_features, categorical_features, scaled=scaled, testing=testing)\n",
    "data_no_use, X_scale, X = prepare_and_scale_data(data, pd.DataFrame(), numeric_features, categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting feature_perturbation = \"tree_path_dependent\" because no background data was given.\n"
     ]
    }
   ],
   "source": [
    "filename_model = 'mymodel_xgboost_largeparty'\n",
    "mymodel, explainer, shap_values, shap_interaction_values, shap_expected_value = shap_Xboost(filename_model, path, data, target, params, X)\n",
    "\n",
    "data.loc[:, \"Ennustettu \" + target] = mymodel.predict(X)\n",
    "from reset_party_number import reset_party_number\n",
    "data, class_names = reset_party_number(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X,  max_display=25,class_names = class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnro = '00520'\n",
    "id_col = 'Postinumero'\n",
    "df, X_rand, prty = shap_proba_individual(explainer, mymodel, data, target, X, id_col, pnro)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_reason(X_rand, explainer, shap_values, mymodel, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(explainer.expected_value[7], explainer.shap_values[7,140], X_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.force_plot(shap_expected_value[1], shap_values[1][2680], X.iloc[1285], link='logit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link='logit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_individual_waterfall(data, target, X, shap_expected_value, shap_values, id_col, pnro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "party = 'KD'\n",
    "idx = class_names.index(party)\n",
    "shap.summary_plot(shap_values[idx], X,  max_display=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "party = 'KESK'\n",
    "idx = class_names.index(party)\n",
    "shap.dependence_plot(\"rank(0)\", shap_values[idx], X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = ['Postinumero','muncipality_name','Asukkaat yhteensä, 2018 (HE)', 'Suurin_puolue', target]\n",
    "show_df, col_list = print_examples(data, X, new, target, 1, shap_values, col_num=9, n=6)\n",
    "show_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_interaction_values[0], X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data['prop'] = np.where(data['Suurin_puolue']==data['Ennustettu Suurin_puolue nimi'],True, False)\n",
    "data[(data['prop']==False) & (data['Ennustettu Suurin_puolue nimi']=='KOK')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(\n",
    "    (col_list[0], col_list[1]),\n",
    "    shap_interaction_values[Party], X,\n",
    "    display_features=X\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
